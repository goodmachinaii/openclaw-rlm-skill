# Architecture

## Flow diagram

```
User (Telegram)
  │
  ▼
OpenClaw Gateway (Node.js, port 18789)
  │ Model: openai-codex/gpt-5.3-codex via OAuth
  │ Already configured and running
  │
  │ [Agent detects history question]
  │ [Reads SKILL.md from rlm-engine]
  │ [Sends "Analyzing your history..." to user]
  │
  ▼
bash tool: cd ~/openclaw-rlm-skill && uv run python src/rlm_bridge.py --query "..."
  │
  ▼
rlm_bridge.py
  ├─ Loads MEMORY.md, SOUL.md, transcripts (auto-detects paths)
  ├─ Limits to 30 sessions / 2M chars (safe for 8GB RAM)
  │
  ▼
RLM (Python)
  ├─ Root LM: gpt-5.3-codex → decides analysis strategy (1 call)
  ├─ Sub-LMs: gpt-5.1-codex-mini → navigate context (2-7 calls, 4x cheaper)
  ├─ System prompt: DEFAULT from alexzhang13 (NO override)
  ├─ Local REPL: executes Python code generated by the model
  │
  ▼
CLIProxyAPI (localhost:8317)
  ├─ Compiled from source (native Go ARM64)
  ├─ Converts API calls to OAuth calls
  ├─ Uses user's ChatGPT subscription ($0 extra)
  │
  ▼
OpenAI servers → response
  │
  ▼
JSON result → OpenClaw → Telegram → User
```

## Components

### 1. OpenClaw Gateway

- Port: 18789
- Receives messages from Telegram
- Detects when to use rlm-engine skill
- Executes bridge via bash

### 2. rlm_bridge.py

Main functions:

| Function | Description |
|----------|-------------|
| `find_sessions_dir()` | Auto-detects where OpenClaw stores sessions |
| `parse_jsonl_session()` | Converts OpenClaw JSONL to readable text |
| `load_workspace()` | Loads MEMORY.md, SOUL.md, daily notes |
| `load_sessions()` | Loads up to 30 sessions (2M chars max) |
| `run_rlm()` | Executes RLM with configured models |

### 3. RLM

- Python library by alexzhang13
- Executes model-generated Python code for reasoning
- Uses local REPL (not Docker) for lower overhead
- max_depth=1 (only functional value currently)

### 4. CLIProxyAPI

- Go proxy that converts OAuth tokens to API calls
- Port: 8317
- Compiled from source (no ARM64 binaries available)
- Management interface: http://localhost:8317/management.html

## Data flow

1. User sends message on Telegram
2. OpenClaw detects deep analysis is needed
3. OpenClaw executes rlm_bridge.py with query
4. Bridge loads context (workspace + sessions)
5. Bridge invokes RLM with context
6. RLM generates and executes Python code for analysis
7. RLM makes API calls via CLIProxyAPI
8. CLIProxyAPI uses ChatGPT OAuth token
9. JSON result returns to OpenClaw
10. OpenClaw responds to user on Telegram

## Memory limits

| Resource | Limit | Reason |
|----------|-------|--------|
| Sessions | 30 | Avoid timeout |
| Characters | 2M | Safe for 8GB RAM |
| Daily notes | 200K chars | Cap for daily notes |
| Workspace files | 50K chars each | Avoid huge files |

## Model strategy

```
User query
  │
  ▼
Root LM (gpt-5.3-codex)
  │ Decides analysis strategy
  │ 1 call
  │
  ├──────────────────┐
  │                  │
  ▼                  ▼
Sub-LM 1          Sub-LM N
(gpt-5.1-codex-mini)
  │ Navigate context
  │ 2-7 calls total
  │ 4x more quota efficient
  │
  ▼
Consolidated result
```
